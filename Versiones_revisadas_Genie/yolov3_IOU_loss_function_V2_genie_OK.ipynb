{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25812cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IOU y Funcion de Perdida de YOLOV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "    else:\n",
    "        raise ValueError(\"box_format debe ser 'midpoint' o 'corners'\")\n",
    "\n",
    "    x1_inter = torch.max(box1_x1, box2_x1)\n",
    "    y1_inter = torch.max(box1_y1, box2_y1)\n",
    "    x2_inter = torch.min(box1_x2, box2_x2)\n",
    "    y2_inter = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2_inter - x1_inter).clamp(0) * (y2_inter - y1_inter).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "    union = box1_area + box2_area - intersection + 1e-6\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "class YOLOv3Loss(nn.Module):\n",
    "    def __init__(self, anchors, num_classes, img_size=(416, 416),\n",
    "                 lambda_coord=1.0, lambda_noobj=1.0, lambda_obj=1.0, lambda_class=1.0,\n",
    "                 ignore_iou_threshold=0.5, device=None):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.lambda_obj = lambda_obj\n",
    "        self.lambda_class = lambda_class\n",
    "        self.ignore_iou_threshold = ignore_iou_threshold\n",
    "\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.0]))\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        obj_loss = 0\n",
    "        noobj_loss = 0\n",
    "        box_loss = 0\n",
    "        class_loss = 0\n",
    "\n",
    "        # Convert anchors to tensor only once, on correct device\n",
    "        anchors_tensor = [torch.tensor(a, dtype=torch.float32, device=self.device) for a in self.anchors]\n",
    "\n",
    "        for scale_idx, prediction in enumerate(predictions):\n",
    "            # prediction: (N, 3*(5+C), H, W)\n",
    "            prediction = prediction.permute(0, 2, 3, 1).reshape(\n",
    "                prediction.shape[0], prediction.shape[2], prediction.shape[3], 3, self.num_classes + 5\n",
    "            )\n",
    "\n",
    "            pred_x_y = prediction[..., 0:2]\n",
    "            pred_w_h = prediction[..., 2:4]\n",
    "            pred_obj = prediction[..., 4:5]\n",
    "            pred_class = prediction[..., 5:]\n",
    "\n",
    "            N, grid_h, grid_w, num_anchors, _ = prediction.shape\n",
    "\n",
    "            anchors_current_scale = anchors_tensor[scale_idx].reshape(1, 1, 1, num_anchors, 2)\n",
    "\n",
    "            # Inicializar todo en el device correcto\n",
    "            target_obj_mask = torch.zeros((N, grid_h, grid_w, num_anchors), dtype=torch.float32, device=self.device)\n",
    "            target_noobj_mask = torch.ones((N, grid_h, grid_w, num_anchors), dtype=torch.float32, device=self.device)\n",
    "            tx = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            ty = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            tw = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            th = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            target_class_one_hot = torch.zeros((N, grid_h, grid_w, num_anchors, self.num_classes), dtype=torch.float32, device=self.device)\n",
    "\n",
    "            # Vectorizar asignaciÃ³n de anchors\n",
    "            if targets.numel() > 0:\n",
    "                # targets: (num_true_boxes_in_batch, 6)\n",
    "                img_ids = targets[:, 0].long()\n",
    "                class_ids = targets[:, 1].long()\n",
    "                x_gt_norm = targets[:, 2]\n",
    "                y_gt_norm = targets[:, 3]\n",
    "                w_gt_norm = targets[:, 4]\n",
    "                h_gt_norm = targets[:, 5]\n",
    "\n",
    "                x_center_grid = x_gt_norm * grid_w\n",
    "                y_center_grid = y_gt_norm * grid_h\n",
    "                cell_x = x_center_grid.long()\n",
    "                cell_y = y_center_grid.long()\n",
    "\n",
    "                # Filtrar targets fuera de grid\n",
    "                grid_mask = (cell_x >= 0) & (cell_x < grid_w) & (cell_y >= 0) & (cell_y < grid_h) & (img_ids >= 0) & (img_ids < N)\n",
    "                img_ids = img_ids[grid_mask]\n",
    "                class_ids = class_ids[grid_mask]\n",
    "                cell_x = cell_x[grid_mask]\n",
    "                cell_y = cell_y[grid_mask]\n",
    "                x_center_grid = x_center_grid[grid_mask]\n",
    "                y_center_grid = y_center_grid[grid_mask]\n",
    "                w_gt_norm = w_gt_norm[grid_mask]\n",
    "                h_gt_norm = h_gt_norm[grid_mask]\n",
    "\n",
    "                # Anchors assignment (vectorized)\n",
    "                w_gt_pix = w_gt_norm * self.img_size[0]\n",
    "                h_gt_pix = h_gt_norm * self.img_size[1]\n",
    "                gt_box_dims = torch.stack([\n",
    "                    torch.zeros_like(w_gt_pix), torch.zeros_like(h_gt_pix), w_gt_pix, h_gt_pix\n",
    "                ], dim=1)  # (num_boxes, 4)\n",
    "\n",
    "                anchor_boxes_for_iou = torch.zeros((num_anchors, 4), device=self.device)\n",
    "                anchor_boxes_for_iou[:, 2] = anchors_current_scale[0,0,0,:,0]\n",
    "                anchor_boxes_for_iou[:, 3] = anchors_current_scale[0,0,0,:,1]\n",
    "\n",
    "                # Expand gt_box_dims for broadcasting\n",
    "                gt_box_dims_exp = gt_box_dims.unsqueeze(1).expand(-1, num_anchors, 4)  # (num_boxes, num_anchors, 4)\n",
    "                anchors_exp = anchor_boxes_for_iou.unsqueeze(0).expand(gt_box_dims.size(0), -1, 4)  # (num_boxes, num_anchors, 4)\n",
    "\n",
    "                ious = intersection_over_union(gt_box_dims_exp, anchors_exp, box_format=\"corners\").squeeze(-1)  # (num_boxes, num_anchors)\n",
    "                best_iou_anchor_idx = torch.argmax(ious, dim=1)  # (num_boxes,)\n",
    "\n",
    "                for idx in range(img_ids.shape[0]):\n",
    "                    i = img_ids[idx]\n",
    "                    c = class_ids[idx]\n",
    "                    cx = cell_x[idx]\n",
    "                    cy = cell_y[idx]\n",
    "                    best_anchor = best_iou_anchor_idx[idx]\n",
    "                    # Masks\n",
    "                    target_obj_mask[i, cy, cx, best_anchor] = 1.0\n",
    "                    target_noobj_mask[i, cy, cx, best_anchor] = 0.0\n",
    "                    # Coordinates\n",
    "                    tx[i, cy, cx, best_anchor] = x_center_grid[idx] - cx\n",
    "                    ty[i, cy, cx, best_anchor] = y_center_grid[idx] - cy\n",
    "                    tw[i, cy, cx, best_anchor] = torch.log(w_gt_pix[idx] / anchors_current_scale[0,0,0,best_anchor,0] + 1e-16)\n",
    "                    th[i, cy, cx, best_anchor] = torch.log(h_gt_pix[idx] / anchors_current_scale[0,0,0,best_anchor,1] + 1e-16)\n",
    "                    # Class\n",
    "                    target_class_one_hot[i, cy, cx, best_anchor, c] = 1.0\n",
    "                    # Ignore anchors with high IoU\n",
    "                    for anchor_idx_other in range(num_anchors):\n",
    "                        if anchor_idx_other == best_anchor:\n",
    "                            continue\n",
    "                        if ious[idx, anchor_idx_other] > self.ignore_iou_threshold:\n",
    "                            target_noobj_mask[i, cy, cx, anchor_idx_other] = 0.0\n",
    "\n",
    "            loss_x = self.bce(pred_x_y[..., 0][target_obj_mask.bool()], tx[target_obj_mask.bool()])\n",
    "            loss_y = self.bce(pred_x_y[..., 1][target_obj_mask.bool()], ty[target_obj_mask.bool()])\n",
    "            loss_w = self.mse(pred_w_h[..., 0][target_obj_mask.bool()], tw[target_obj_mask.bool()])\n",
    "            loss_h = self.mse(pred_w_h[..., 1][target_obj_mask.bool()], th[target_obj_mask.bool()])\n",
    "            box_loss += (loss_x + loss_y + loss_w + loss_h)\n",
    "\n",
    "            loss_obj = self.bce(pred_obj[target_obj_mask.bool()], target_obj_mask[target_obj_mask.bool()].float().unsqueeze(-1))\n",
    "            loss_noobj = self.bce(pred_obj[target_noobj_mask.bool()], target_noobj_mask[target_noobj_mask.bool()].float().unsqueeze(-1))\n",
    "            obj_loss += loss_obj\n",
    "            noobj_loss += loss_noobj\n",
    "\n",
    "            loss_class = self.bce(pred_class[target_obj_mask.bool()], target_class_one_hot[target_obj_mask.bool()])\n",
    "            class_loss += loss_class\n",
    "\n",
    "        total_loss = (\n",
    "            self.lambda_coord * box_loss\n",
    "            + self.lambda_obj * obj_loss\n",
    "            + self.lambda_noobj * noobj_loss\n",
    "            + self.lambda_class * class_loss\n",
    "        )\n",
    "        return total_loss, {\"box_loss\": box_loss, \"obj_loss\": obj_loss, \"noobj_loss\": noobj_loss, \"class_loss\": class_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c4b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando device: cpu\n",
      "\n",
      "--- Ejecutando la funciÃ³n de pÃ©rdida con datos dummy ---\n",
      "\n",
      "PÃ©rdida Total: 23.2065\n",
      "  PÃ©rdida de Cajas (box_loss): 15.4137\n",
      "  PÃ©rdida de Objeto (obj_loss): 2.6371\n",
      "  PÃ©rdida de No-objeto (noobj_loss): 2.4228\n",
      "  PÃ©rdida de Clase (class_loss): 2.7329\n",
      "\n",
      "La funciÃ³n de pÃ©rdida se ejecutÃ³ exitosamente con valores numÃ©ricos vÃ¡lidos.\n",
      "\n",
      "--- Fin de la prueba ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# --- ParÃ¡metros para la prueba ---\n",
    "NUM_CLASSES = 3\n",
    "IMG_SIZE = (416, 416)\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Anchors (los tuyos)\n",
    "ANCHORS = [\n",
    "    [(227, 210), (179, 155), (124, 111)],\n",
    "    [(105, 113), (104, 96), (80, 109)],\n",
    "    [(112, 75), (87, 82), (39, 38)]\n",
    "]\n",
    "\n",
    "# --- SelecciÃ³n dinÃ¡mica de device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando device: {device}\")\n",
    "\n",
    "# --- Instanciar la funciÃ³n de pÃ©rdida ---\n",
    "\n",
    "# IOU y Funcion de Perdida de YOLOV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "    else:\n",
    "        raise ValueError(\"box_format debe ser 'midpoint' o 'corners'\")\n",
    "\n",
    "    x1_inter = torch.max(box1_x1, box2_x1)\n",
    "    y1_inter = torch.max(box1_y1, box2_y1)\n",
    "    x2_inter = torch.min(box1_x2, box2_x2)\n",
    "    y2_inter = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2_inter - x1_inter).clamp(0) * (y2_inter - y1_inter).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "    union = box1_area + box2_area - intersection + 1e-6\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "class YOLOv3Loss(nn.Module):\n",
    "    def __init__(self, anchors, num_classes, img_size=(416, 416),\n",
    "                lambda_coord=1.0, lambda_noobj=1.0, lambda_obj=1.0, lambda_class=1.0,\n",
    "                ignore_iou_threshold=0.5, device=None):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.lambda_obj = lambda_obj\n",
    "        self.lambda_class = lambda_class\n",
    "        self.ignore_iou_threshold = ignore_iou_threshold\n",
    "\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.0]))\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        obj_loss = 0\n",
    "        noobj_loss = 0\n",
    "        box_loss = 0\n",
    "        class_loss = 0\n",
    "\n",
    "        # Convert anchors to tensor only once, on correct device\n",
    "        anchors_tensor = [torch.tensor(a, dtype=torch.float32, device=self.device) for a in self.anchors]\n",
    "\n",
    "        for scale_idx, prediction in enumerate(predictions):\n",
    "            # prediction: (N, 3*(5+C), H, W)\n",
    "            prediction = prediction.permute(0, 2, 3, 1).reshape(\n",
    "                prediction.shape[0], prediction.shape[2], prediction.shape[3], 3, self.num_classes + 5\n",
    "            )\n",
    "\n",
    "            pred_x_y = prediction[..., 0:2]\n",
    "            pred_w_h = prediction[..., 2:4]\n",
    "            pred_obj = prediction[..., 4:5]\n",
    "            pred_class = prediction[..., 5:]\n",
    "\n",
    "            N, grid_h, grid_w, num_anchors, _ = prediction.shape\n",
    "\n",
    "            anchors_current_scale = anchors_tensor[scale_idx].reshape(1, 1, 1, num_anchors, 2)\n",
    "\n",
    "            # Inicializar todo en el device correcto\n",
    "            target_obj_mask = torch.zeros((N, grid_h, grid_w, num_anchors), dtype=torch.float32, device=self.device)\n",
    "            target_noobj_mask = torch.ones((N, grid_h, grid_w, num_anchors), dtype=torch.float32, device=self.device)\n",
    "            tx = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            ty = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            tw = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            th = torch.zeros((N, grid_h, grid_w, num_anchors), device=self.device)\n",
    "            target_class_one_hot = torch.zeros((N, grid_h, grid_w, num_anchors, self.num_classes), dtype=torch.float32, device=self.device)\n",
    "\n",
    "            # Vectorizar asignaciÃ³n de anchors\n",
    "            if targets.numel() > 0:\n",
    "                # targets: (num_true_boxes_in_batch, 6)\n",
    "                img_ids = targets[:, 0].long()\n",
    "                class_ids = targets[:, 1].long()\n",
    "                x_gt_norm = targets[:, 2]\n",
    "                y_gt_norm = targets[:, 3]\n",
    "                w_gt_norm = targets[:, 4]\n",
    "                h_gt_norm = targets[:, 5]\n",
    "\n",
    "                x_center_grid = x_gt_norm * grid_w\n",
    "                y_center_grid = y_gt_norm * grid_h\n",
    "                cell_x = x_center_grid.long()\n",
    "                cell_y = y_center_grid.long()\n",
    "\n",
    "                # Filtrar targets fuera de grid\n",
    "                grid_mask = (cell_x >= 0) & (cell_x < grid_w) & (cell_y >= 0) & (cell_y < grid_h) & (img_ids >= 0) & (img_ids < N)\n",
    "                img_ids = img_ids[grid_mask]\n",
    "                class_ids = class_ids[grid_mask]\n",
    "                cell_x = cell_x[grid_mask]\n",
    "                cell_y = cell_y[grid_mask]\n",
    "                x_center_grid = x_center_grid[grid_mask]\n",
    "                y_center_grid = y_center_grid[grid_mask]\n",
    "                w_gt_norm = w_gt_norm[grid_mask]\n",
    "                h_gt_norm = h_gt_norm[grid_mask]\n",
    "\n",
    "                # Anchors assignment (vectorized)\n",
    "                w_gt_pix = w_gt_norm * self.img_size[0]\n",
    "                h_gt_pix = h_gt_norm * self.img_size[1]\n",
    "                gt_box_dims = torch.stack([\n",
    "                    torch.zeros_like(w_gt_pix), torch.zeros_like(h_gt_pix), w_gt_pix, h_gt_pix\n",
    "                ], dim=1)  # (num_boxes, 4)\n",
    "\n",
    "                anchor_boxes_for_iou = torch.zeros((num_anchors, 4), device=self.device)\n",
    "                anchor_boxes_for_iou[:, 2] = anchors_current_scale[0,0,0,:,0]\n",
    "                anchor_boxes_for_iou[:, 3] = anchors_current_scale[0,0,0,:,1]\n",
    "\n",
    "                # Expand gt_box_dims for broadcasting\n",
    "                gt_box_dims_exp = gt_box_dims.unsqueeze(1).expand(-1, num_anchors, 4)  # (num_boxes, num_anchors, 4)\n",
    "                anchors_exp = anchor_boxes_for_iou.unsqueeze(0).expand(gt_box_dims.size(0), -1, 4)  # (num_boxes, num_anchors, 4)\n",
    "\n",
    "                ious = intersection_over_union(gt_box_dims_exp, anchors_exp, box_format=\"corners\").squeeze(-1)  # (num_boxes, num_anchors)\n",
    "                best_iou_anchor_idx = torch.argmax(ious, dim=1)  # (num_boxes,)\n",
    "\n",
    "                for idx in range(img_ids.shape[0]):\n",
    "                    i = img_ids[idx]\n",
    "                    c = class_ids[idx]\n",
    "                    cx = cell_x[idx]\n",
    "                    cy = cell_y[idx]\n",
    "                    best_anchor = best_iou_anchor_idx[idx]\n",
    "                    # Masks\n",
    "                    target_obj_mask[i, cy, cx, best_anchor] = 1.0\n",
    "                    target_noobj_mask[i, cy, cx, best_anchor] = 0.0\n",
    "                    # Coordinates\n",
    "                    tx[i, cy, cx, best_anchor] = x_center_grid[idx] - cx\n",
    "                    ty[i, cy, cx, best_anchor] = y_center_grid[idx] - cy\n",
    "                    tw[i, cy, cx, best_anchor] = torch.log(w_gt_pix[idx] / anchors_current_scale[0,0,0,best_anchor,0] + 1e-16)\n",
    "                    th[i, cy, cx, best_anchor] = torch.log(h_gt_pix[idx] / anchors_current_scale[0,0,0,best_anchor,1] + 1e-16)\n",
    "                    # Class\n",
    "                    target_class_one_hot[i, cy, cx, best_anchor, c] = 1.0\n",
    "                    # Ignore anchors with high IoU\n",
    "                    for anchor_idx_other in range(num_anchors):\n",
    "                        if anchor_idx_other == best_anchor:\n",
    "                            continue\n",
    "                        if ious[idx, anchor_idx_other] > self.ignore_iou_threshold:\n",
    "                            target_noobj_mask[i, cy, cx, anchor_idx_other] = 0.0\n",
    "\n",
    "            loss_x = self.bce(pred_x_y[..., 0][target_obj_mask.bool()], tx[target_obj_mask.bool()])\n",
    "            loss_y = self.bce(pred_x_y[..., 1][target_obj_mask.bool()], ty[target_obj_mask.bool()])\n",
    "            loss_w = self.mse(pred_w_h[..., 0][target_obj_mask.bool()], tw[target_obj_mask.bool()])\n",
    "            loss_h = self.mse(pred_w_h[..., 1][target_obj_mask.bool()], th[target_obj_mask.bool()])\n",
    "            box_loss += (loss_x + loss_y + loss_w + loss_h)\n",
    "\n",
    "            loss_obj = self.bce(pred_obj[target_obj_mask.bool()], target_obj_mask[target_obj_mask.bool()].float().unsqueeze(-1))\n",
    "            loss_noobj = self.bce(pred_obj[target_noobj_mask.bool()], target_noobj_mask[target_noobj_mask.bool()].float().unsqueeze(-1))\n",
    "            obj_loss += loss_obj\n",
    "            noobj_loss += loss_noobj\n",
    "\n",
    "            loss_class = self.bce(pred_class[target_obj_mask.bool()], target_class_one_hot[target_obj_mask.bool()])\n",
    "            class_loss += loss_class\n",
    "\n",
    "        total_loss = (\n",
    "            self.lambda_coord * box_loss\n",
    "            + self.lambda_obj * obj_loss\n",
    "            + self.lambda_noobj * noobj_loss\n",
    "            + self.lambda_class * class_loss\n",
    "        )\n",
    "        return total_loss, {\"box_loss\": box_loss, \"obj_loss\": obj_loss, \"noobj_loss\": noobj_loss, \"class_loss\": class_loss}\n",
    "\n",
    "loss_fn = YOLOv3Loss(\n",
    "    anchors=ANCHORS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    img_size=IMG_SIZE,\n",
    "    lambda_coord=1.0,\n",
    "    lambda_noobj=1.0,\n",
    "    lambda_obj=1.0,\n",
    "    lambda_class=1.0,\n",
    "    ignore_iou_threshold=0.5,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# --- Crear predicciones dummy ---\n",
    "pred0_grid_h, pred0_grid_w = IMG_SIZE[0] // 32, IMG_SIZE[1] // 32\n",
    "pred1_grid_h, pred1_grid_w = IMG_SIZE[0] // 16, IMG_SIZE[1] // 16\n",
    "pred2_grid_h, pred2_grid_w = IMG_SIZE[0] // 8, IMG_SIZE[1] // 8\n",
    "\n",
    "predictions_dummy = [\n",
    "    torch.randn(BATCH_SIZE, 3 * (5 + NUM_CLASSES), pred0_grid_h, pred0_grid_w, device=device),\n",
    "    torch.randn(BATCH_SIZE, 3 * (5 + NUM_CLASSES), pred1_grid_h, pred1_grid_w, device=device),\n",
    "    torch.randn(BATCH_SIZE, 3 * (5 + NUM_CLASSES), pred2_grid_h, pred2_grid_w, device=device)\n",
    "]\n",
    "\n",
    "# --- Crear targets dummy ---\n",
    "targets_dummy = torch.tensor([\n",
    "    [0, 0, 0.5, 0.5, 0.1, 0.1],\n",
    "    [0, 1, 0.2, 0.8, 0.05, 0.05],\n",
    "    [0, 2, 0.7, 0.3, 0.2, 0.2],\n",
    "    [1, 0, 0.1, 0.1, 0.3, 0.3],\n",
    "    [1, 1, 0.9, 0.9, 0.08, 0.08],\n",
    "], dtype=torch.float32, device=device)\n",
    "\n",
    "# --- Ejecutar la funciÃ³n de pÃ©rdida ---\n",
    "print(\"\\n--- Ejecutando la funciÃ³n de pÃ©rdida con datos dummy ---\")\n",
    "total_loss, individual_losses = loss_fn(predictions_dummy, targets_dummy)\n",
    "\n",
    "print(f\"\\nPÃ©rdida Total: {total_loss.item():.4f}\")\n",
    "print(f\"  PÃ©rdida de Cajas (box_loss): {individual_losses['box_loss'].item():.4f}\")\n",
    "print(f\"  PÃ©rdida de Objeto (obj_loss): {individual_losses['obj_loss'].item():.4f}\")\n",
    "print(f\"  PÃ©rdida de No-objeto (noobj_loss): {individual_losses['noobj_loss'].item():.4f}\")\n",
    "print(f\"  PÃ©rdida de Clase (class_loss): {individual_losses['class_loss'].item():.4f}\")\n",
    "\n",
    "if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "    print(\"\\nÂ¡Advertencia! La pÃ©rdida total es NaN o Inf. Esto indica un problema numÃ©rico.\")\n",
    "else:\n",
    "    print(\"\\nLa funciÃ³n de pÃ©rdida se ejecutÃ³ exitosamente con valores numÃ©ricos vÃ¡lidos.\")\n",
    "\n",
    "print(\"\\n--- Fin de la prueba ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_13042025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
