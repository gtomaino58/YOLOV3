{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188f2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de la funcion IOU y de la funcion de perdida para YOLOv3\n",
    "# Incluyo ambas cosas en la misma celda para que se puedan probar juntas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# PASO 1: Definicion de la función intersection_over_union\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Calcula la Intersection Over Union (IoU) entre bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        boxes_preds (tensor): Bounding boxes predichas de forma (N, 4) o (batch_size, 4)\n",
    "                            donde N es el número de cajas o 1 si es una sola caja.\n",
    "                            Formato de las cajas: (x, y, w, h) o (x1, y1, x2, y2).\n",
    "        boxes_labels (tensor): Bounding boxes ground truth de forma (N, 4) o (batch_size, 4).\n",
    "        box_format (str): Formato de las cajas de entrada.\n",
    "                        \"midpoint\" si es (x_center, y_center, width, height)\n",
    "                        \"corners\" si es (x1, y1, x2, y2).\n",
    "\n",
    "    Returns:\n",
    "        tensor: IoU para cada par de cajas, de forma (N, 1) o (batch_size, 1).\n",
    "    \"\"\"\n",
    "\n",
    "    if box_format == \"midpoint\":\n",
    "        # Convertir de (x_center, y_center, width, height) a (x1, y1, x2, y2)\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        \n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    elif box_format == \"corners\":\n",
    "        # Asumir que ya están en (x1, y1, x2, y2)\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        \n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "    else:\n",
    "        raise ValueError(\"box_format debe ser 'midpoint' o 'corners'\")\n",
    "\n",
    "    # Calcular las coordenadas del rectángulo de intersección\n",
    "    x1_inter = torch.max(box1_x1, box2_x1)\n",
    "    y1_inter = torch.max(box1_y1, box2_y1)\n",
    "    x2_inter = torch.min(box1_x2, box2_x2)\n",
    "    y2_inter = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Calcular el área de intersección\n",
    "    intersection = (x2_inter - x1_inter).clamp(0) * \\\n",
    "                (y2_inter - y1_inter).clamp(0)\n",
    "\n",
    "    # Calcular el área de cada bounding box\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    # Calcular el IoU\n",
    "    union = box1_area + box2_area - intersection + 1e-6 # Añadir epsilon para evitar división por cero\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou\n",
    "\n",
    "# PASO 2: Definición de la clase YOLOv3Loss\n",
    "\n",
    "class YOLOv3Loss(nn.Module):\n",
    "    def __init__(self, anchors, num_classes, img_size=(416, 416), \n",
    "                lambda_coord=1.0, lambda_noobj=1.0, lambda_obj=1.0, lambda_class=1.0, \n",
    "                ignore_iou_threshold=0.5): # Umbral para ignorar anchors en noobj loss\n",
    "        super().__init__()\n",
    "        self.anchors = anchors \n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.lambda_coord = lambda_coord \n",
    "        self.lambda_noobj = lambda_noobj \n",
    "        self.lambda_obj = lambda_obj     \n",
    "        self.lambda_class = lambda_class \n",
    "        self.ignore_iou_threshold = ignore_iou_threshold \n",
    "\n",
    "        self.mse = nn.MSELoss() \n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.0])) \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        obj_loss = 0\n",
    "        noobj_loss = 0\n",
    "        box_loss = 0\n",
    "        class_loss = 0 \n",
    "\n",
    "        for scale_idx, prediction in enumerate(predictions):\n",
    "            prediction = prediction.permute(0, 2, 3, 1).reshape(\n",
    "                prediction.shape[0], prediction.shape[2], prediction.shape[3], 3, self.num_classes + 5\n",
    "            )\n",
    "            \n",
    "            pred_x_y = prediction[..., 0:2] \n",
    "            pred_w_h = prediction[..., 2:4]                 \n",
    "            pred_obj = prediction[..., 4:5]               \n",
    "            pred_class = prediction[..., 5:]               \n",
    "\n",
    "            N, grid_h, grid_w, num_anchors, _ = prediction.shape\n",
    "            \n",
    "            anchors_current_scale = torch.tensor(self.anchors[scale_idx], device=targets.device).reshape(1, 1, 1, num_anchors, 2)\n",
    "            \n",
    "            target_obj_mask = torch.zeros((N, grid_h, grid_w, num_anchors), dtype=torch.float32, device=targets.device)\n",
    "            target_noobj_mask = torch.ones((N, grid_h, grid_w, num_anchors), dtype=torch.float32, device=targets.device)\n",
    "            \n",
    "            tx = torch.zeros((N, grid_h, grid_w, num_anchors), device=targets.device)\n",
    "            ty = torch.zeros((N, grid_h, grid_w, num_anchors), device=targets.device)\n",
    "            tw = torch.zeros((N, grid_h, grid_w, num_anchors), device=targets.device) \n",
    "            th = torch.zeros((N, grid_h, grid_w, num_anchors), device=targets.device) \n",
    "            \n",
    "            target_class_one_hot = torch.zeros((N, grid_h, grid_w, num_anchors, self.num_classes), dtype=torch.float32, device=targets.device) \n",
    "\n",
    "            for box_idx in range(targets.shape[0]):\n",
    "                img_id, class_id, x_gt_norm, y_gt_norm, w_gt_norm, h_gt_norm = targets[box_idx].tolist()\n",
    "                img_id = int(img_id) \n",
    "\n",
    "                x_center_grid = x_gt_norm * grid_w\n",
    "                y_center_grid = y_gt_norm * grid_h\n",
    "                \n",
    "                cell_x = int(x_center_grid)\n",
    "                cell_y = int(y_center_grid)\n",
    "\n",
    "                if cell_x >= grid_w or cell_y >= grid_h or cell_x < 0 or cell_y < 0:\n",
    "                    continue\n",
    "                \n",
    "                w_gt_abs_pixels = w_gt_norm * self.img_size[0]\n",
    "                h_gt_abs_pixels = h_gt_norm * self.img_size[1]\n",
    "                \n",
    "                gt_box_dims = torch.tensor([0, 0, w_gt_abs_pixels, h_gt_abs_pixels], device=targets.device)\n",
    "\n",
    "                anchor_boxes_for_iou = torch.zeros((num_anchors, 4), device=targets.device)\n",
    "                anchor_boxes_for_iou[:, 2] = anchors_current_scale[0,0,0,:,0] \n",
    "                anchor_boxes_for_iou[:, 3] = anchors_current_scale[0,0,0,:,1] \n",
    "                \n",
    "                ious = intersection_over_union(\n",
    "                    gt_box_dims.unsqueeze(0), \n",
    "                    anchor_boxes_for_iou,     \n",
    "                    box_format=\"corners\"      \n",
    "                ) \n",
    "                \n",
    "                best_iou_anchor_idx = torch.argmax(ious).item() \n",
    "                \n",
    "                target_obj_mask[img_id, cell_y, cell_x, best_iou_anchor_idx] = 1.0 \n",
    "                target_noobj_mask[img_id, cell_y, cell_x, best_iou_anchor_idx] = 0.0 \n",
    "                \n",
    "                tx[img_id, cell_y, cell_x, best_iou_anchor_idx] = x_center_grid - cell_x\n",
    "                ty[img_id, cell_y, cell_x, best_iou_anchor_idx] = y_center_grid - cell_y\n",
    "                \n",
    "                tw[img_id, cell_y, cell_x, best_iou_anchor_idx] = torch.log(w_gt_abs_pixels / anchors_current_scale[0,0,0,best_iou_anchor_idx,0] + 1e-16) \n",
    "                th[img_id, cell_y, cell_x, best_iou_anchor_idx] = torch.log(h_gt_abs_pixels / anchors_current_scale[0,0,0,best_iou_anchor_idx,1] + 1e-16) \n",
    "                \n",
    "                target_class_one_hot[img_id, cell_y, cell_x, best_iou_anchor_idx, int(class_id)] = 1.0 \n",
    "\n",
    "                for anchor_idx_other, iou_val in enumerate(ious[0]): \n",
    "                    if anchor_idx_other == best_iou_anchor_idx:\n",
    "                        continue \n",
    "                    \n",
    "                    if iou_val > self.ignore_iou_threshold:\n",
    "                        target_noobj_mask[img_id, cell_y, cell_x, anchor_idx_other] = 0.0 \n",
    "            \n",
    "            loss_x = self.bce(pred_x_y[..., 0][target_obj_mask.bool()], tx[target_obj_mask.bool()])\n",
    "            loss_y = self.bce(pred_x_y[..., 1][target_obj_mask.bool()], ty[target_obj_mask.bool()])\n",
    "\n",
    "            loss_w = self.mse(pred_w_h[..., 0][target_obj_mask.bool()], tw[target_obj_mask.bool()]) \n",
    "            loss_h = self.mse(pred_w_h[..., 1][target_obj_mask.bool()], th[target_obj_mask.bool()]) \n",
    "            \n",
    "            box_loss += (loss_x + loss_y + loss_w + loss_h)\n",
    "\n",
    "            loss_obj = self.bce(pred_obj[target_obj_mask.bool()], target_obj_mask[target_obj_mask.bool()].float().unsqueeze(-1))\n",
    "            loss_noobj = self.bce(pred_obj[target_noobj_mask.bool()], target_noobj_mask[target_noobj_mask.bool()].float().unsqueeze(-1))\n",
    "            \n",
    "            obj_loss += loss_obj\n",
    "            noobj_loss += loss_noobj\n",
    "\n",
    "            loss_class = self.bce(pred_class[target_obj_mask.bool()], target_class_one_hot[target_obj_mask.bool()])\n",
    "            class_loss += loss_class\n",
    "\n",
    "        total_loss = (\n",
    "            self.lambda_coord * box_loss\n",
    "            + self.lambda_obj * obj_loss\n",
    "            + self.lambda_noobj * noobj_loss\n",
    "            + self.lambda_class * class_loss\n",
    "        )\n",
    "        return total_loss, {\"box_loss\": box_loss, \"obj_loss\": obj_loss, \"noobj_loss\": noobj_loss, \"class_loss\": class_loss}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea269071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejemplo 1: Cajas superpuestas (formato 'corners') ---\n",
      "IoU (corners): 0.1428571492433548\n",
      "\n",
      "--- Ejemplo 2: Cajas idénticas (formato 'midpoint') ---\n",
      "IoU (midpoint, idénticas): 1.0\n",
      "\n",
      "--- Ejemplo 3: Cajas sin superposición (formato 'corners') ---\n",
      "IoU (corners, sin superposición): 0.0\n",
      "\n",
      "--- Ejemplo 4: Cajas con una dimensión cero (para probar clamp) ---\n",
      "IoU (corners, ancho cero): 0.0\n",
      "\n",
      "--- Ejemplo 5: Cajas con diferentes tamaños (formato 'midpoint') ---\n",
      "IoU (midpoint, diferentes tamaños): 0.25\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función intersection_over_union\n",
    "\n",
    "# import torch\n",
    "# Asegúrate de que la función intersection_over_union esté accesible,\n",
    "# por ejemplo, si la tienes en un archivo llamado 'utils.py', la importarías así:\n",
    "# from utils import intersection_over_union\n",
    "\n",
    "# --- Ejemplo 1: Cajas superpuestas (formato 'corners') ---\n",
    "print(\"--- Ejemplo 1: Cajas superpuestas (formato 'corners') ---\")\n",
    "box1 = torch.tensor([[0.0, 0.0, 10.0, 10.0]]) # Caja 1: (0,0) a (10,10)\n",
    "box2 = torch.tensor([[5.0, 5.0, 15.0, 15.0]]) # Caja 2: (5,5) a (15,15)\n",
    "# Intersección: (5,5) a (10,10) -> Ancho 5, Alto 5 -> Área = 25\n",
    "# Área box1 = 100, Área box2 = 100\n",
    "# Unión = 100 + 100 - 25 = 175\n",
    "# IoU esperado = 25 / 175 = 0.1428...\n",
    "\n",
    "iou_result = intersection_over_union(box1, box2, box_format=\"corners\")\n",
    "print(f\"IoU (corners): {iou_result.item()}\")\n",
    "# Debería ser aproximadamente 0.142857\n",
    "\n",
    "# --- Ejemplo 2: Cajas idénticas (formato 'midpoint') ---\n",
    "print(\"\\n--- Ejemplo 2: Cajas idénticas (formato 'midpoint') ---\")\n",
    "# Caja 1: centro (5,5), ancho 10, alto 10 -> (0,0) a (10,10)\n",
    "box1_mid = torch.tensor([[5.0, 5.0, 10.0, 10.0]])\n",
    "# Caja 2: centro (5,5), ancho 10, alto 10 -> (0,0) a (10,10)\n",
    "box2_mid = torch.tensor([[5.0, 5.0, 10.0, 10.0]])\n",
    "# IoU esperado = 1.0 (cajas idénticas)\n",
    "\n",
    "iou_result_mid = intersection_over_union(box1_mid, box2_mid, box_format=\"midpoint\")\n",
    "print(f\"IoU (midpoint, idénticas): {iou_result_mid.item()}\")\n",
    "# Debería ser 1.0\n",
    "\n",
    "# --- Ejemplo 3: Cajas sin superposición (formato 'corners') ---\n",
    "print(\"\\n--- Ejemplo 3: Cajas sin superposición (formato 'corners') ---\")\n",
    "box1_no_overlap = torch.tensor([[0.0, 0.0, 10.0, 10.0]])\n",
    "box2_no_overlap = torch.tensor([[11.0, 11.0, 20.0, 20.0]])\n",
    "# IoU esperado = 0.0\n",
    "\n",
    "iou_result_no_overlap = intersection_over_union(box1_no_overlap, box2_no_overlap, box_format=\"corners\")\n",
    "print(f\"IoU (corners, sin superposición): {iou_result_no_overlap.item()}\")\n",
    "# Debería ser 0.0\n",
    "\n",
    "# --- Ejemplo 4: Cajas con una dimensión cero (para probar clamp) ---\n",
    "print(\"\\n--- Ejemplo 4: Cajas con una dimensión cero (para probar clamp) ---\")\n",
    "box1_zero_width = torch.tensor([[0.0, 0.0, 0.0, 10.0]]) # Ancho cero\n",
    "box2_zero_width = torch.tensor([[0.0, 0.0, 5.0, 10.0]])\n",
    "# IoU esperado = 0.0 (o un valor muy pequeño debido al epsilon)\n",
    "\n",
    "iou_result_zero_width = intersection_over_union(box1_zero_width, box2_zero_width, box_format=\"corners\")\n",
    "print(f\"IoU (corners, ancho cero): {iou_result_zero_width.item()}\")\n",
    "# Debería ser 0.0 (o cercano a cero)\n",
    "\n",
    "# --- Ejemplo 5: Cajas con diferentes tamaños (formato 'midpoint') ---\n",
    "print(\"\\n--- Ejemplo 5: Cajas con diferentes tamaños (formato 'midpoint') ---\")\n",
    "# box1: centro (10,10), w=10, h=10 -> (5,5) a (15,15)\n",
    "box1_diff = torch.tensor([[10.0, 10.0, 10.0, 10.0]])\n",
    "# box2: centro (10,10), w=5, h=5 -> (7.5,7.5) a (12.5,12.5)\n",
    "box2_diff = torch.tensor([[10.0, 10.0, 5.0, 5.0]])\n",
    "# box1_area = 100, box2_area = 25\n",
    "# Intersección = 25 (box2 está completamente dentro de box1)\n",
    "# Unión = 100 + 25 - 25 = 100\n",
    "# IoU esperado = 25 / 100 = 0.25\n",
    "\n",
    "iou_result_diff = intersection_over_union(box1_diff, box2_diff, box_format=\"midpoint\")\n",
    "print(f\"IoU (midpoint, diferentes tamaños): {iou_result_diff.item()}\")\n",
    "# Debería ser 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f7522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ejecutando la función de pérdida con datos dummy ---\n",
      "\n",
      "Pérdida Total: 22.9507\n",
      "  Pérdida de Cajas (box_loss): 16.0573\n",
      "  Pérdida de Objeto (obj_loss): 2.1578\n",
      "  Pérdida de No-objeto (noobj_loss): 2.4027\n",
      "  Pérdida de Clase (class_loss): 2.3329\n",
      "\n",
      "La función de pérdida se ejecutó exitosamente con valores numéricos válidos.\n",
      "\n",
      "--- Fin de la prueba ---\n",
      "\n",
      "--- Fin de la prueba ---\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la funcion loss de YOLOv3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuración para la prueba ---\n",
    "    NUM_CLASSES = 3 # RBC, WBC, Platelets\n",
    "    IMG_SIZE = (416, 416)\n",
    "    BATCH_SIZE = 2 # Tamaño de lote para la prueba\n",
    "\n",
    "    # Anchors para YOLOv3 (ejemplo de COCO para 416x416)\n",
    "    # Debes usar los anchors que sean adecuados para tu dataset\n",
    "    #ANCHORS = [\n",
    "    #    [(10, 13), (16, 30), (33, 23)],  # Escala 0 (grid 13x13)\n",
    "    #    [(30, 61), (62, 45), (59, 119)], # Escala 1 (grid 26x26)\n",
    "    #    [(116, 90), (156, 198), (373, 326)], # Escala 2 (grid 52x52)\n",
    "    #]\n",
    "    \n",
    "    ANCHORS = [\n",
    "    [(227, 210), (179, 155), (124, 111)],  # Anchors para la escala más grande (stride 32, detecta objetos grandes)\n",
    "    [(105, 113), (104, 96), (80, 109)],    # Anchors para la escala media (stride 16, detecta objetos medianos)\n",
    "    [(112, 75), (87, 82), (39, 38)]        # Anchors para la escala más pequeña (stride 8, detecta objetos pequeños)\n",
    "]\n",
    "    \n",
    "    # Convertir anchors a tensores de PyTorch para pasarlos a la pérdida\n",
    "    ANCHORS_TENSOR = [torch.tensor(a) for a in ANCHORS]\n",
    "\n",
    "    # --- Instanciar la función de pérdida ---\n",
    "    loss_fn = YOLOv3Loss(\n",
    "        anchors=ANCHORS, # Pasamos la lista de Python, la clase la convertirá a tensor\n",
    "        num_classes=NUM_CLASSES,\n",
    "        img_size=IMG_SIZE,\n",
    "        lambda_coord=1.0,\n",
    "        lambda_noobj=1.0,\n",
    "        lambda_obj=1.0,\n",
    "        lambda_class=1.0,\n",
    "        ignore_iou_threshold=0.5\n",
    "    )\n",
    "\n",
    "    # --- Crear predicciones dummy (simulando la salida del modelo) ---\n",
    "    # La salida del modelo son 3 tensores, uno por cada escala.\n",
    "    # Formato: (N, 3 * (5 + num_classes), Grid_H, Grid_W)\n",
    "\n",
    "    # Predicciones para la escala 0 (grid 13x13)\n",
    "    pred0_grid_h, pred0_grid_w = IMG_SIZE[0] // 32, IMG_SIZE[1] // 32 # 13x13\n",
    "    predictions0 = torch.randn(BATCH_SIZE, 3 * (5 + NUM_CLASSES), pred0_grid_h, pred0_grid_w)\n",
    "\n",
    "    # Predicciones para la escala 1 (grid 26x26)\n",
    "    pred1_grid_h, pred1_grid_w = IMG_SIZE[0] // 16, IMG_SIZE[1] // 16 # 26x26\n",
    "    predictions1 = torch.randn(BATCH_SIZE, 3 * (5 + NUM_CLASSES), pred1_grid_h, pred1_grid_w)\n",
    "\n",
    "    # Predicciones para la escala 2 (grid 52x52)\n",
    "    pred2_grid_h, pred2_grid_w = IMG_SIZE[0] // 8, IMG_SIZE[1] // 8 # 52x52\n",
    "    predictions2 = torch.randn(BATCH_SIZE, 3 * (5 + NUM_CLASSES), pred2_grid_h, pred2_grid_w)\n",
    "\n",
    "    predictions_dummy = [predictions0, predictions1, predictions2]\n",
    "\n",
    "    # --- Crear targets dummy (simulando las ground truth boxes) ---\n",
    "    # Formato: (num_true_boxes_in_batch, 6) -> (image_idx, class_id, x_norm, y_norm, w_norm, h_norm)\n",
    "    # x,y,w,h normalizados globalmente [0,1]\n",
    "    targets_dummy = torch.tensor([\n",
    "        [0, 0, 0.5, 0.5, 0.1, 0.1],   # Imagen 0, Clase 0, centro, caja pequeña\n",
    "        [0, 1, 0.2, 0.8, 0.05, 0.05], # Imagen 0, Clase 1, abajo-izquierda, caja muy pequeña\n",
    "        [0, 2, 0.7, 0.3, 0.2, 0.2],   # Imagen 0, Clase 2, arriba-derecha, caja mediana\n",
    "        [1, 0, 0.1, 0.1, 0.3, 0.3],   # Imagen 1, Clase 0, arriba-izquierda, caja grande\n",
    "        [1, 1, 0.9, 0.9, 0.08, 0.08], # Imagen 1, Clase 1, abajo-derecha, caja pequeña\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    # Mover a la GPU si está disponible\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    predictions_dummy = [p.to(device) for p in predictions_dummy]\n",
    "    targets_dummy = targets_dummy.to(device)\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    # --- Ejecutar la función de pérdida ---\n",
    "    print(\"\\n--- Ejecutando la función de pérdida con datos dummy ---\")\n",
    "    total_loss, individual_losses = loss_fn(predictions_dummy, targets_dummy)\n",
    "\n",
    "    print(f\"\\nPérdida Total: {total_loss.item():.4f}\")\n",
    "    print(f\"  Pérdida de Cajas (box_loss): {individual_losses['box_loss'].item():.4f}\")\n",
    "    print(f\"  Pérdida de Objeto (obj_loss): {individual_losses['obj_loss'].item():.4f}\")\n",
    "    print(f\"  Pérdida de No-objeto (noobj_loss): {individual_losses['noobj_loss'].item():.4f}\")\n",
    "    print(f\"  Pérdida de Clase (class_loss): {individual_losses['class_loss'].item():.4f}\")\n",
    "\n",
    "    # --- Verificaciones básicas (opcional) ---\n",
    "    # Si las pérdidas son NaN o inf, algo anda mal.\n",
    "    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "        print(\"\\n¡Advertencia! La pérdida total es NaN o Inf. Esto indica un problema numérico.\")\n",
    "    else:\n",
    "        print(\"\\nLa función de pérdida se ejecutó exitosamente con valores numéricos válidos.\")\n",
    "\n",
    "    print(\"\\n--- Fin de la prueba ---\")\n",
    "    print(\"\\n--- Fin de la prueba ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_13042025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
