{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fb3b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando anotaciones desde: C:/Users/gtoma/Master_AI_Aplicada/GitHubRep/PyTorch-YOLOv3/dataset\\annotations.csv\n",
      "Total de 4886 bounding boxes válidas cargadas para clustering.\n",
      "\n",
      "Ejecutando K-means para encontrar 9 anchor boxes...\n",
      "Iniciando K-means con 9 centroides iniciales:\n",
      "[[ 98.  59.]\n",
      " [ 71.  77.]\n",
      " [116.  89.]\n",
      " [106.  83.]\n",
      " [128. 131.]\n",
      " [108. 101.]\n",
      " [104.  99.]\n",
      " [126.  73.]\n",
      " [ 34.  39.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ejecutando K-means:  25%|██▍       | 74/300 [14:06<43:06, 11.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means convergió en la iteración 75.\n",
      "\n",
      "--- Anchor Boxes Calculadas (Formato para YOLOv3Loss) ---\n",
      "[[(227, 210), (179, 155), (124, 111)], [(105, 113), (104, 96), (80, 109)], [(112, 75), (87, 82), (39, 38)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IoU promedio de clustering: 0.8765\n",
      "\n",
      "Guarda estas anchor boxes para usarlas en la instanciación de tu modelo YOLOv3 y tu función de pérdida.\n"
     ]
    }
   ],
   "source": [
    "# Vammos a calcular las anchor boxes para YOLOv3 usando K-means con IoU como métrica de distancia.\n",
    "# Este script asume que tienes un archivo CSV con las anotaciones de las bounding boxes.\n",
    "# Asegúrate de que tienes las librerías necesarias instaladas:\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm # Para barras de progreso\n",
    "import random # Para inicialización de K-means\n",
    "\n",
    "# Asegúrate de que la función intersection_over_union esté accesible\n",
    "# Si la tienes en utils.py, impórtala:\n",
    "# from utils import intersection_over_union\n",
    "# Si no, la definimos aquí para que el script sea autocontenido:\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        \n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        \n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "    else:\n",
    "        raise ValueError(\"box_format debe ser 'midpoint' o 'corners'\")\n",
    "\n",
    "    # Calcular las coordenadas del rectángulo de intersección\n",
    "    # Aseguramos que estas variables estén definidas después de los ifs\n",
    "    x1_inter = torch.max(box1_x1, box2_x1)\n",
    "    y1_inter = torch.max(box1_y1, box2_y1)\n",
    "    x2_inter = torch.min(box1_x2, box2_x2)\n",
    "    y2_inter = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Calcular el área de intersección\n",
    "    intersection = (x2_inter - x1_inter).clamp(0) * \\\n",
    "                    (y2_inter - y1_inter).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    union = box1_area + box2_area - intersection + 1e-6\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "def iou_distance(box, centroid):\n",
    "    \"\"\"\n",
    "    Calcula la \"distancia\" como 1 - IoU, para usar en K-means.\n",
    "    Las cajas se asumen centradas en (0,0) para comparar solo dimensiones.\n",
    "    Args:\n",
    "        box (np.array): [width, height] de una bounding box.\n",
    "        centroid (np.array): [width, height] de un centroide (anchor).\n",
    "    Returns:\n",
    "        float: 1 - IoU entre la caja y el centroide.\n",
    "    \"\"\"\n",
    "    box_tensor = torch.tensor([[0.0, 0.0, box[0], box[1]]], dtype=torch.float32)\n",
    "    centroid_tensor = torch.tensor([[0.0, 0.0, centroid[0], centroid[1]]], dtype=torch.float32)\n",
    "    \n",
    "    # Usamos box_format=\"corners\" porque las estamos tratando como (x1, y1, x2, y2)\n",
    "    # donde x1,y1 son 0 y x2,y2 son width, height.\n",
    "    iou = intersection_over_union(box_tensor, centroid_tensor, box_format=\"corners\").item()\n",
    "    return 1 - iou # Queremos minimizar la \"distancia\", que es 1 - IoU\n",
    "\n",
    "def calculate_average_iou(boxes, centroids):\n",
    "    \"\"\"\n",
    "    Calcula el IoU promedio entre las cajas y sus centroides asignados.\n",
    "    \"\"\"\n",
    "    total_iou = 0.0\n",
    "    num_boxes = 0\n",
    "    for box in boxes:\n",
    "        best_iou = -1\n",
    "        for centroid in centroids:\n",
    "            iou = 1 - iou_distance(box, centroid)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "        total_iou += best_iou\n",
    "        num_boxes += 1\n",
    "    return total_iou / num_boxes if num_boxes > 0 else 0.0\n",
    "\n",
    "\n",
    "def kmeans_iou(boxes, k, max_iters=100, tol=1e-6, random_seed=42):\n",
    "    \"\"\"\n",
    "    Implementación de K-means que utiliza 1 - IoU como métrica de distancia.\n",
    "    Args:\n",
    "        boxes (np.array): Array de dimensiones de bounding boxes (N, 2), donde N es el número de cajas.\n",
    "                        Cada fila es [width, height].\n",
    "        k (int): Número de clusters (número de anchor boxes a generar).\n",
    "        max_iters (int): Número máximo de iteraciones.\n",
    "        tol (float): Tolerancia para la convergencia.\n",
    "        random_seed (int): Semilla para la reproducibilidad.\n",
    "    Returns:\n",
    "        np.array: Centroides finales (anchor boxes).\n",
    "    \"\"\"\n",
    "    # 1. Inicialización de los centroides (K-means++ como aproximación simplificada: elige k puntos aleatorios)\n",
    "    # Opcional: Para una inicialización más robusta, podrías implementar K-means++ completo\n",
    "    random.seed(random_seed)\n",
    "    centroids = np.array(random.sample(list(boxes), k)).astype(np.float32) # Convertir a float32\n",
    "\n",
    "    print(f\"Iniciando K-means con {k} centroides iniciales:\")\n",
    "    print(centroids)\n",
    "\n",
    "    for iteration in tqdm(range(max_iters), desc=\"Ejecutando K-means\"):\n",
    "        # 2. Asignación: Asigna cada caja al centroide más cercano (con menor 1-IoU)\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        for i, box in enumerate(boxes):\n",
    "            distances = [iou_distance(box, centroid) for centroid in centroids]\n",
    "            closest_centroid_idx = np.argmin(distances)\n",
    "            clusters[closest_centroid_idx].append(box)\n",
    "\n",
    "        # 3. Actualización: Recalcula los centroides (promedio de las cajas asignadas)\n",
    "        new_centroids = np.zeros_like(centroids)\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            if cluster: # Evitar división por cero si un cluster está vacío\n",
    "                new_centroids[i] = np.mean(cluster, axis=0)\n",
    "            else:\n",
    "                # Si un cluster está vacío, re-inicializarlo con una caja aleatoria\n",
    "                new_centroids[i] = random.choice(list(boxes))\n",
    "\n",
    "        # 4. Comprobar convergencia\n",
    "        # Calculamos el desplazamiento máximo de los centroides\n",
    "        # Usamos 1 - IoU como \"distancia\" entre centroides para la convergencia\n",
    "        max_centroid_shift = 0.0\n",
    "        for i in range(k):\n",
    "            shift = iou_distance(centroids[i], new_centroids[i])\n",
    "            if shift > max_centroid_shift:\n",
    "                max_centroid_shift = shift\n",
    "        \n",
    "        centroids = new_centroids\n",
    "\n",
    "        if max_centroid_shift < tol:\n",
    "            print(f\"K-means convergió en la iteración {iteration + 1}.\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"K-means alcanzó el número máximo de iteraciones ({max_iters}) sin converger con la tolerancia {tol}.\")\n",
    "\n",
    "    return centroids\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuración ---\n",
    "    DATA_ROOT = 'C:/Users/gtoma/Master_AI_Aplicada/GitHubRep/PyTorch-YOLOv3/dataset'\n",
    "    CSV_FILE = os.path.join(DATA_ROOT, 'annotations.csv')\n",
    "    NUM_ANCHORS = 9 # Para YOLOv3, suelen ser 9 anchors\n",
    "    \n",
    "    # --- 1. Cargar las dimensiones de todas las bounding boxes ---\n",
    "    print(f\"Cargando anotaciones desde: {CSV_FILE}\")\n",
    "    try:\n",
    "        annotations_df = pd.read_csv(CSV_FILE)\n",
    "        # Asegurarse de que no haya NaN y convertir a int\n",
    "        annotations_df = annotations_df.dropna(subset=['xmin', 'ymin', 'xmax', 'ymax'])\n",
    "        annotations_df[['xmin', 'ymin', 'xmax', 'ymax']] = annotations_df[['xmin', 'ymin', 'xmax', 'ymax']].astype(int)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Archivo CSV no encontrado en {CSV_FILE}\")\n",
    "        exit()\n",
    "\n",
    "    # Calcular ancho y alto de cada caja\n",
    "    # original_w y original_h son necesarios para desnormalizar si el CSV ya está normalizado.\n",
    "    # En este dataset BCCD, las coordenadas son en píxeles.\n",
    "    annotations_df['width'] = annotations_df['xmax'] - annotations_df['xmin']\n",
    "    annotations_df['height'] = annotations_df['ymax'] - annotations_df['ymin']\n",
    "\n",
    "    # Filtrar cajas degeneradas (ancho o alto <= 0)\n",
    "    filtered_boxes = annotations_df[(annotations_df['width'] > 0) & (annotations_df['height'] > 0)]\n",
    "\n",
    "    # Extraer solo las dimensiones [width, height]\n",
    "    # Asegúrate de que las dimensiones sean coherentes con tu img_size si están normalizadas.\n",
    "    # Si tu CSV tiene (x,y,w,h) normalizados, deberías multiplicarlos por el tamaño de la imagen original\n",
    "    # para obtener dimensiones en píxeles para el clustering.\n",
    "    # Como BCCD tiene píxeles, ya está bien.\n",
    "    all_box_dimensions = filtered_boxes[['width', 'height']].values.astype(np.float32)\n",
    "\n",
    "    if len(all_box_dimensions) == 0:\n",
    "        print(\"No se encontraron bounding boxes válidas para el clustering. Revisa tu CSV y filtros.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Total de {len(all_box_dimensions)} bounding boxes válidas cargadas para clustering.\")\n",
    "\n",
    "    # --- 2. Ejecutar K-means con métrica IoU ---\n",
    "    print(f\"\\nEjecutando K-means para encontrar {NUM_ANCHORS} anchor boxes...\")\n",
    "    anchor_centroids = kmeans_iou(all_box_dimensions, k=NUM_ANCHORS, max_iters=300, tol=1e-5)\n",
    "\n",
    "    # --- 3. Ordenar y Formatear los resultados ---\n",
    "    # Ordenar los anchors por tamaño (ej. área o ancho) para asignarlos a las escalas.\n",
    "    # YOLOv3 típicamente usa los 3 más grandes para la escala más pequeña (grid 13x13),\n",
    "    # los 3 medianos para la escala media (grid 26x26), y los 3 más pequeños para la escala más grande (grid 52x52).\n",
    "    \n",
    "    # Ordenar por área para asegurar que los anchors más grandes vayan a la escala adecuada.\n",
    "    # anchor_centroids es np.array([[w1,h1], [w2,h2], ...])\n",
    "    anchor_centroids = anchor_centroids[np.argsort(anchor_centroids[:, 0] * anchor_centroids[:, 1])]\n",
    "    \n",
    "    # Dividir en 3 grupos (para 3 escalas) y formatear\n",
    "    # Asignación sugerida:\n",
    "    # Scale 0 (grid más pequeño, stride 32): 3 anchors más grandes\n",
    "    # Scale 1 (grid medio, stride 16): 3 anchors medianos\n",
    "    # Scale 2 (grid más grande, stride 8): 3 anchors más pequeños\n",
    "\n",
    "    # Invertir el orden para que los más grandes estén primero\n",
    "    anchor_centroids = anchor_centroids[::-1] \n",
    "\n",
    "    # Agrupar para las 3 escalas de YOLOv3 (si NUM_ANCHORS es 9)\n",
    "    # anchors_per_scale = NUM_ANCHORS // 3\n",
    "    # anchors_scale0 = anchor_centroids[0:anchors_per_scale]\n",
    "    # anchors_scale1 = anchor_centroids[anchors_per_scale:2*anchors_per_scale]\n",
    "    # anchors_scale2 = anchor_centroids[2*anchors_per_scale:3*anchors_per_scale]\n",
    "\n",
    "    # Para YOLOv3, se suelen usar 3 anclas por escala. Las anclas se pasan a la Loss Function\n",
    "    # como una lista de listas de tuplas: [[(w,h), (w,h), (w,h)], ... ]\n",
    "    # y en el orden de las escalas de la red:\n",
    "    # [anchors_for_scale_0 (largest grid), anchors_for_scale_1 (medium grid), anchors_for_scale_2 (smallest grid)]\n",
    "    # NO: el orden de los anclas es Smallest grid -> largest objects. Esto significa que la primera sub-lista\n",
    "    # de ANCHORS debería corresponder a la capa de salida con el stride más grande (e.g., 13x13 grid for 416x416).\n",
    "    # Esa capa detecta objetos grandes.\n",
    "\n",
    "    # Ordenarlos por área y agruparlos de mayor a menor para asignarlos a las escalas\n",
    "    # Los más grandes (índices 0, 1, 2) van a la escala 0 (grid 13x13)\n",
    "    # Los medianos (índices 3, 4, 5) van a la escala 1 (grid 26x26)\n",
    "    # Los más pequeños (índices 6, 7, 8) van a la escala 2 (grid 52x52)\n",
    "\n",
    "    # Aseguramos el orden de las anclas de mayor a menor\n",
    "    sorted_anchors = []\n",
    "    for anchor in anchor_centroids:\n",
    "        sorted_anchors.append(tuple(anchor.round(2).astype(int))) # Redondeamos y convertimos a entero para tuplas\n",
    "\n",
    "    # Formato final para la Loss Function\n",
    "    # Este es el formato de ANCHORS que se pasa a YOLOv3Loss\n",
    "    final_anchors = [\n",
    "        sorted_anchors[0:3], # Las 3 más grandes (para grid 13x13)\n",
    "        sorted_anchors[3:6], # Las 3 medianas (para grid 26x26)\n",
    "        sorted_anchors[6:9], # Las 3 más pequeñas (para grid 52x52)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Anchor Boxes Calculadas (Formato para YOLOv3Loss) ---\")\n",
    "    print(final_anchors)\n",
    "\n",
    "    average_iou = calculate_average_iou(all_box_dimensions, anchor_centroids)\n",
    "    print(f\"\\nIoU promedio de clustering: {average_iou:.4f}\")\n",
    "\n",
    "    print(\"\\nGuarda estas anchor boxes para usarlas en la instanciación de tu modelo YOLOv3 y tu función de pérdida.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baaa9e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando anotaciones desde: C:/Users/gtoma/Master_AI_Aplicada/GitHubRep/PyTorch-YOLOv3/dataset\\annotations.csv\n",
      "Total de 4886 bounding boxes válidas cargadas para clustering.\n",
      "\n",
      "Ejecutando K-means para encontrar 9 anchor boxes...\n",
      "Iniciando K-means con 9 centroides iniciales:\n",
      "[[ 98.  59.]\n",
      " [ 71.  77.]\n",
      " [116.  89.]\n",
      " [106.  83.]\n",
      " [128. 131.]\n",
      " [108. 101.]\n",
      " [104.  99.]\n",
      " [126.  73.]\n",
      " [ 34.  39.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ejecutando K-means:  25%|██▍       | 74/300 [09:20<28:32,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means convergió en la iteración 75.\n",
      "\n",
      "--- Anchor Boxes Calculadas (Formato para YOLOv3Loss) ---\n",
      "[[(227, 210), (179, 155), (124, 111)], [(105, 113), (104, 96), (80, 109)], [(112, 75), (87, 82), (39, 38)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IoU promedio de clustering: 0.8765\n",
      "\n",
      "Guarda estas anchor boxes para usarlas en la instanciación de tu modelo YOLOv3 y tu función de pérdida.\n"
     ]
    }
   ],
   "source": [
    "# Otra version del mismo script\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm # Para barras de progreso\n",
    "import random # Para inicialización de K-means\n",
    "\n",
    "# Asegúrate de que la función intersection_over_union esté accesible\n",
    "# Si la tienes en utils.py, impórtala:\n",
    "# from utils import intersection_over_union\n",
    "# Si no, la definimos aquí para que el script sea autocontenido:\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        \n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        \n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "    else:\n",
    "        raise ValueError(\"box_format debe ser 'midpoint' o 'corners'\")\n",
    "\n",
    "    # Calcular las coordenadas del rectángulo de intersección\n",
    "    # Aseguramos que estas variables estén definidas después de los ifs\n",
    "    x1_inter = torch.max(box1_x1, box2_x1)\n",
    "    y1_inter = torch.max(box1_y1, box2_y1)\n",
    "    x2_inter = torch.min(box1_x2, box2_x2)\n",
    "    y2_inter = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Calcular el área de intersección\n",
    "    intersection = (x2_inter - x1_inter).clamp(0) * \\\n",
    "                    (y2_inter - y1_inter).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    union = box1_area + box2_area - intersection + 1e-6\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "def iou_distance(box, centroid):\n",
    "    \"\"\"\n",
    "    Calcula la \"distancia\" como 1 - IoU, para usar en K-means.\n",
    "    Las cajas se asumen centradas en (0,0) para comparar solo dimensiones.\n",
    "    Args:\n",
    "        box (np.array): [width, height] de una bounding box.\n",
    "        centroid (np.array): [width, height] de un centroide (anchor).\n",
    "    Returns:\n",
    "        float: 1 - IoU entre la caja y el centroide.\n",
    "    \"\"\"\n",
    "    box_tensor = torch.tensor([[0.0, 0.0, box[0], box[1]]], dtype=torch.float32)\n",
    "    centroid_tensor = torch.tensor([[0.0, 0.0, centroid[0], centroid[1]]], dtype=torch.float32)\n",
    "    \n",
    "    # Usamos box_format=\"corners\" porque las estamos tratando como (x1, y1, x2, y2)\n",
    "    # donde x1,y1 son 0 y x2,y2 son width, height.\n",
    "    iou = intersection_over_union(box_tensor, centroid_tensor, box_format=\"corners\").item()\n",
    "    return 1 - iou # Queremos minimizar la \"distancia\", que es 1 - IoU\n",
    "\n",
    "def calculate_average_iou(boxes, centroids):\n",
    "    \"\"\"\n",
    "    Calcula el IoU promedio entre las cajas y sus centroides asignados.\n",
    "    \"\"\"\n",
    "    total_iou = 0.0\n",
    "    num_boxes = 0\n",
    "    for box in boxes:\n",
    "        best_iou = -1\n",
    "        for centroid in centroids:\n",
    "            iou = 1 - iou_distance(box, centroid)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "        total_iou += best_iou\n",
    "        num_boxes += 1\n",
    "    return total_iou / num_boxes if num_boxes > 0 else 0.0\n",
    "\n",
    "\n",
    "def kmeans_iou(boxes, k, max_iters=100, tol=1e-6, random_seed=42):\n",
    "    \"\"\"\n",
    "    Implementación de K-means que utiliza 1 - IoU como métrica de distancia.\n",
    "    Args:\n",
    "        boxes (np.array): Array de dimensiones de bounding boxes (N, 2), donde N es el número de cajas.\n",
    "                        Cada fila es [width, height].\n",
    "        k (int): Número de clusters (número de anchor boxes a generar).\n",
    "        max_iters (int): Número máximo de iteraciones.\n",
    "        tol (float): Tolerancia para la convergencia.\n",
    "        random_seed (int): Semilla para la reproducibilidad.\n",
    "    Returns:\n",
    "        np.array: Centroides finales (anchor boxes).\n",
    "    \"\"\"\n",
    "    # 1. Inicialización de los centroides (K-means++ como aproximación simplificada: elige k puntos aleatorios)\n",
    "    # Opcional: Para una inicialización más robusta, podrías implementar K-means++ completo\n",
    "    random.seed(random_seed)\n",
    "    centroids = np.array(random.sample(list(boxes), k)).astype(np.float32) # Convertir a float32\n",
    "\n",
    "    print(f\"Iniciando K-means con {k} centroides iniciales:\")\n",
    "    print(centroids)\n",
    "\n",
    "    for iteration in tqdm(range(max_iters), desc=\"Ejecutando K-means\"):\n",
    "        # 2. Asignación: Asigna cada caja al centroide más cercano (con menor 1-IoU)\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        for i, box in enumerate(boxes):\n",
    "            distances = [iou_distance(box, centroid) for centroid in centroids]\n",
    "            closest_centroid_idx = np.argmin(distances)\n",
    "            clusters[closest_centroid_idx].append(box)\n",
    "\n",
    "        # 3. Actualización: Recalcula los centroides (promedio de las cajas asignadas)\n",
    "        new_centroids = np.zeros_like(centroids)\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            if cluster: # Evitar división por cero si un cluster está vacío\n",
    "                new_centroids[i] = np.mean(cluster, axis=0)\n",
    "            else:\n",
    "                # Si un cluster está vacío, re-inicializarlo con una caja aleatoria\n",
    "                new_centroids[i] = random.choice(list(boxes))\n",
    "\n",
    "        # 4. Comprobar convergencia\n",
    "        # Calculamos el desplazamiento máximo de los centroides\n",
    "        # Usamos 1 - IoU como \"distancia\" entre centroides para la convergencia\n",
    "        max_centroid_shift = 0.0\n",
    "        for i in range(k):\n",
    "            shift = iou_distance(centroids[i], new_centroids[i])\n",
    "            if shift > max_centroid_shift:\n",
    "                max_centroid_shift = shift\n",
    "        \n",
    "        centroids = new_centroids\n",
    "\n",
    "        if max_centroid_shift < tol:\n",
    "            print(f\"K-means convergió en la iteración {iteration + 1}.\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"K-means alcanzó el número máximo de iteraciones ({max_iters}) sin converger con la tolerancia {tol}.\")\n",
    "\n",
    "    return centroids\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuración ---\n",
    "    DATA_ROOT = 'C:/Users/gtoma/Master_AI_Aplicada/GitHubRep/PyTorch-YOLOv3/dataset'\n",
    "    CSV_FILE = os.path.join(DATA_ROOT, 'annotations.csv')\n",
    "    NUM_ANCHORS = 9 # Para YOLOv3, suelen ser 9 anchors\n",
    "    \n",
    "    # --- 1. Cargar las dimensiones de todas las bounding boxes ---\n",
    "    print(f\"Cargando anotaciones desde: {CSV_FILE}\")\n",
    "    try:\n",
    "        annotations_df = pd.read_csv(CSV_FILE)\n",
    "        # Asegurarse de que no haya NaN y convertir a int\n",
    "        annotations_df = annotations_df.dropna(subset=['xmin', 'ymin', 'xmax', 'ymax'])\n",
    "        annotations_df[['xmin', 'ymin', 'xmax', 'ymax']] = annotations_df[['xmin', 'ymin', 'xmax', 'ymax']].astype(int)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Archivo CSV no encontrado en {CSV_FILE}\")\n",
    "        exit()\n",
    "\n",
    "    # Calcular ancho y alto de cada caja\n",
    "    # original_w y original_h son necesarios para desnormalizar si el CSV ya está normalizado.\n",
    "    # En este dataset BCCD, las coordenadas son en píxeles.\n",
    "    annotations_df['width'] = annotations_df['xmax'] - annotations_df['xmin']\n",
    "    annotations_df['height'] = annotations_df['ymax'] - annotations_df['ymin']\n",
    "\n",
    "    # Filtrar cajas degeneradas (ancho o alto <= 0)\n",
    "    filtered_boxes = annotations_df[(annotations_df['width'] > 0) & (annotations_df['height'] > 0)]\n",
    "\n",
    "    # Extraer solo las dimensiones [width, height]\n",
    "    # Asegúrate de que las dimensiones sean coherentes con tu img_size si están normalizadas.\n",
    "    # Si tu CSV tiene (x,y,w,h) normalizados, deberías multiplicarlos por el tamaño de la imagen original\n",
    "    # para obtener dimensiones en píxeles para el clustering.\n",
    "    # Como BCCD tiene píxeles, ya está bien.\n",
    "    all_box_dimensions = filtered_boxes[['width', 'height']].values.astype(np.float32)\n",
    "\n",
    "    if len(all_box_dimensions) == 0:\n",
    "        print(\"No se encontraron bounding boxes válidas para el clustering. Revisa tu CSV y filtros.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Total de {len(all_box_dimensions)} bounding boxes válidas cargadas para clustering.\")\n",
    "\n",
    "    # --- 2. Ejecutar K-means con métrica IoU ---\n",
    "    print(f\"\\nEjecutando K-means para encontrar {NUM_ANCHORS} anchor boxes...\")\n",
    "    anchor_centroids = kmeans_iou(all_box_dimensions, k=NUM_ANCHORS, max_iters=300, tol=1e-5)\n",
    "\n",
    "    # --- 3. Ordenar y Formatear los resultados ---\n",
    "    # Ordenar los anchors por tamaño (ej. área o ancho) para asignarlos a las escalas.\n",
    "    # YOLOv3 típicamente usa los 3 más grandes para la escala más pequeña (grid 13x13),\n",
    "    # los 3 medianos para la escala media (grid 26x26), y los 3 más pequeños para la escala más grande (grid 52x52).\n",
    "    \n",
    "    # Ordenar por área para asegurar que los anchors más grandes vayan a la escala adecuada.\n",
    "    # anchor_centroids es np.array([[w1,h1], [w2,h2], ...])\n",
    "    anchor_centroids = anchor_centroids[np.argsort(anchor_centroids[:, 0] * anchor_centroids[:, 1])]\n",
    "    \n",
    "    # Dividir en 3 grupos (para 3 escalas) y formatear\n",
    "    # Asignación sugerida:\n",
    "    # Scale 0 (grid más pequeño, stride 32): 3 anchors más grandes\n",
    "    # Scale 1 (grid medio, stride 16): 3 anchors medianos\n",
    "    # Scale 2 (grid más grande, stride 8): 3 anchors más pequeños\n",
    "\n",
    "    # Invertir el orden para que los más grandes estén primero\n",
    "    anchor_centroids = anchor_centroids[::-1] \n",
    "\n",
    "    # Agrupar para las 3 escalas de YOLOv3 (si NUM_ANCHORS es 9)\n",
    "    # anchors_per_scale = NUM_ANCHORS // 3\n",
    "    # anchors_scale0 = anchor_centroids[0:anchors_per_scale]\n",
    "    # anchors_scale1 = anchor_centroids[anchors_per_scale:2*anchors_per_scale]\n",
    "    # anchors_scale2 = anchor_centroids[2*anchors_per_scale:3*anchors_per_scale]\n",
    "\n",
    "    # Para YOLOv3, se suelen usar 3 anclas por escala. Las anclas se pasan a la Loss Function\n",
    "    # como una lista de listas de tuplas: [[(w,h), (w,h), (w,h)], ... ]\n",
    "    # y en el orden de las escalas de la red:\n",
    "    # [anchors_for_scale_0 (largest grid), anchors_for_scale_1 (medium grid), anchors_for_scale_2 (smallest grid)]\n",
    "    # NO: el orden de los anclas es Smallest grid -> largest objects. Esto significa que la primera sub-lista\n",
    "    # de ANCHORS debería corresponder a la capa de salida con el stride más grande (e.g., 13x13 grid for 416x416).\n",
    "    # Esa capa detecta objetos grandes.\n",
    "\n",
    "    # Ordenarlos por área y agruparlos de mayor a menor para asignarlos a las escalas\n",
    "    # Los más grandes (índices 0, 1, 2) van a la escala 0 (grid 13x13)\n",
    "    # Los medianos (índices 3, 4, 5) van a la escala 1 (grid 26x26)\n",
    "    # Los más pequeños (índices 6, 7, 8) van a la escala 2 (grid 52x52)\n",
    "\n",
    "    # Aseguramos el orden de las anclas de mayor a menor\n",
    "    sorted_anchors = []\n",
    "    for anchor in anchor_centroids:\n",
    "        sorted_anchors.append(tuple(anchor.round(2).astype(int))) # Redondeamos y convertimos a entero para tuplas\n",
    "\n",
    "    # Formato final para la Loss Function\n",
    "    # Este es el formato de ANCHORS que se pasa a YOLOv3Loss\n",
    "    final_anchors = [\n",
    "        sorted_anchors[0:3], # Las 3 más grandes (para grid 13x13)\n",
    "        sorted_anchors[3:6], # Las 3 medianas (para grid 26x26)\n",
    "        sorted_anchors[6:9], # Las 3 más pequeñas (para grid 52x52)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Anchor Boxes Calculadas (Formato para YOLOv3Loss) ---\")\n",
    "    print(final_anchors)\n",
    "\n",
    "    average_iou = calculate_average_iou(all_box_dimensions, anchor_centroids)\n",
    "    print(f\"\\nIoU promedio de clustering: {average_iou:.4f}\")\n",
    "\n",
    "    print(\"\\nGuarda estas anchor boxes para usarlas en la instanciación de tu modelo YOLOv3 y tu función de pérdida.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_13042025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
